[pytest]
# Consolidated Test Configuration
# Root + E2E tests merged into single config
testpaths = tests/integration/api_smoke tests_e2e
python_files = test_*.py
python_classes = Test*
python_functions = test_*
norecursedirs = implementation .git .venv __pycache__ .pytest_cache scripts app/tests tests/manual tests/manual_integration tests/e2e_frontend tests/features tests/debug .archive

# Logging (from tests_e2e config)
log_cli = true
log_cli_level = INFO
log_cli_format = %(asctime)s [%(levelname)8s] %(message)s
log_cli_date_format = %Y-%m-%d %H:%M:%S

# Failure behavior (from tests_e2e config)
addopts =
    --strict-markers
    --tb=short
    --maxfail=1
    -ra

# Custom markers - CONSOLIDATED (all markers from both configs)
markers =
    # E2E Test Markers
    e2e: End-to-end tests with Playwright or Selenium
    golden_path: Production critical Golden Path tests (DO NOT SKIP - deployment blocker)
    smoke: Fast smoke tests for CI regression checks
    regression: Regression protection tests for known production bugs
    critical: Build blocker tests - must pass before deployment
    component: Component-level tests (UI components, isolated features)

    # Integration Critical (Production Gate)
    integration_critical: Critical multi-role integration flows (BLOCKING production gate)

    # User Lifecycle Markers (P0 - Production Critical)
    user_lifecycle: User activation tests (registration, onboarding, auth)
    registration: User registration flows
    onboarding: User onboarding workflows
    ui: UI-based test (Streamlit/Playwright)
    invitation_ui: Invitation code UI tests
    coupon_ui: Coupon UI tests

    # Business Workflow Markers (P1 - Production Critical)
    business_workflow: Business logic workflows (instructor, admin, player)
    instructor: Instructor workflow tests
    admin: Admin workflow tests

    # Tournament Format Markers (P2)
    h2h: HEAD_TO_HEAD tournament tests (League + Knockout)
    individual_ranking: INDIVIDUAL_RANKING tournament tests (15 configurations)
    group_knockout: GROUP_AND_KNOCKOUT tournament tests (Group Stage + Knockout)
    group_stage: GROUP_STAGE_ONLY tests (Group Stage without Knockout)

    # Test Level Markers
    unit: Unit tests for isolated component testing
    integration: Integration tests for multi-component interactions
    postgres: Tests requiring PostgreSQL database
    requires_worker: Tests requiring background worker (async/celery)

    # Lifecycle Phases (from tests_e2e)
    lifecycle: Lifecycle phase tests (ordered, state-dependent)
    phase_0: Phase 0 — Clean DB setup
    phase_1: Phase 1 — User registration
    phase_2: Phase 2 — Onboarding
    phase_3: Phase 3 — Enrollment/license
    phase_4: Phase 4 — Tournament lifecycle
    phase_5: Phase 5 — Skill progression coverage
    phase_6: Phase 6 — Edge cardinality system-safety tests
    phase_7: Phase 7 — Session result submission E2E (session-scoped HEAD_TO_HEAD)
    phase_7b: Phase 7b — Session INDIVIDUAL result submission E2E (full workflow)
    priority_1: Priority 1 — Tournament manual creation lifecycle (T1-T4 state machine)
    priority_2: Priority 2 — Session check-in lifecycle (S1 state transition)
    priority_3: Priority 3 — Session lifecycle completion (S5-S6 archival & cancellation)
    priority_4: Priority 4 — Reward distribution WITH reward policy (R2 financial integrity)
    priority_k1: Priority K1 — Skill assessment lifecycle (state machine, validation, concurrency)

    # Reward System Markers
    reward_distribution: Reward distribution and financial integrity tests
    reward_policy: Reward policy tests

    # Skill Assessment Lifecycle Markers (Priority K1)
    skill_lifecycle: Skill assessment lifecycle tests (state machine, idempotency, concurrency)
    full_lifecycle: Full lifecycle tests (NOT_ASSESSED → ASSESSED → VALIDATED → ARCHIVED)
    invalid_transitions: Invalid state transition rejection tests
    idempotency: Idempotency tests (create/validate/archive twice)
    edge_cases: Edge case tests (comprehensive invalid transitions, auto-archive scenarios)
    business_rules: Business rule validation tests (validation requirement determination)
    auto_archive: Auto-archive logic tests (replacement scenarios)

    # Performance & Scale (from tests_e2e)
    skill_progression: Skill-level assertions (delta ordering, EMA state, clamp)
    edge_cardinality: Edge player-count tests (odd, dynamic distribution, large brackets)
    nondestructive: Tests that do not modify any state (pure read/in-process computation only)
    scale_structural: In-process structural tests for large-cardinality tournament engine validation (no DB/server)
    production_flow: Live server + real DB + Celery worker required — full operator lifecycle validation (production readiness)
    concurrency: Parallel tournament generation stress test — validates queue behaviour, worker utilisation, and DB write serialisation under concurrent load
    large_field_monitor: 1024-player knockout + dual-mode Playwright browser validation of Tournament Monitor with event propagation latency measurement
    tournament_monitor: Headless Playwright tests for OPS Tournament Monitor UI, wizard flow, and live tracking panel
    ops_seed: Tests requiring 64 @lfa-seed.hu seed players (Fast Suite boundary tests 2-64)
    scale_suite: Tests requiring 128-1024 players (Scale Suite - optional execution, capacity validation)
    slow: Tests with long runtime (>30s)

    # Component Markers
    tournament: Tournament-related tests
    tournament_workflow: Complete tournament workflow tests (end-to-end)
    validation: Business logic validation tests
    api: API endpoint tests
    api_integration: API integration tests (FastAPI TestClient + DB)
    skip: Tests to skip (for debugging/manual runs only)

# pytest-selenium: only treat production domains as sensitive, not localhost
sensitive_url = (https?://(www\.)?lfa\.(com|hu|io))
